{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모두를 위한 머신러닝/딥러닝 강의\n",
    "김성훈 교수님의 모두를 위한 머신러닝/딥러닝 강의 중 lab 강의 코드입니다.\n",
    "## Lab12_1 RNN basics\n",
    "본 자료에서는 학습은 다루지않고 tensorflow에서 rnn 계열을 다루기위한 함수들의 input, output의 형태와 forward 과정에서 어떤 함수를 써야하는 지를 다룹니다.  \n",
    "\n",
    "참고 : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf  \n",
    "*(RNN의 case : one to one, one to man, many to one, many to many 등은 위의 pdf를 참고)*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "# http://learningtensorflow.com/index.html\n",
    "# http://suriyadeepan.github.io/2016-12-31-practical-seq2seq/\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pprint\n",
    "from tensorflow.contrib import rnn\n",
    "tf.set_random_seed(777)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One to One : RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 다음과 같은 경우이다. Rank = 3 짜리의 array 또는 list로 input과 output을 다룬다.\n",
    "![Alt text](http://i.imgur.com/PiVFGpy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "[[[ 1.  0.  0.  0.]]] (1, 1, 4)\n",
      "cell states [[-0.54783535  0.16807944]]\n",
      "outputs [[[-0.54783535  0.16807944]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('basic_rnn_one_cell'):\n",
    "# 실제 RNN의 경우 cell state라고는 통칭하지않으나 LSTM의 cell state와 hidden state의 짝을 맞춰주기위해 cell state라고 명명\n",
    "# One cell Rnn input_dim (4) -> output_dim (2) 여기서는 RNN의 경우 cell state의 차원 수\n",
    "\n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "    print(cell.state_size, cell.output_size)\n",
    "    \n",
    "    # cell에 state와 output 두 개가 있는 이유는 state는 다시 다음 state에 건네주기위함이고 output은 실제 출력 y를 계산하기위한 vector\n",
    "    # RNN의 경우 state와 output이 같다. (둘다 한 번 forward 된 hidden node의 값)\n",
    "    \n",
    "    x_data = np.array([[h]], dtype = np.float32) # x_data = [[[1,0,0,0]]]\n",
    "    print(x_data, x_data.shape)\n",
    "    \n",
    "    # forward\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_data, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('cell states', states.eval())\n",
    "    print('outputs', outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One to One : LSTM\n",
    "RNN과는 달리 cell state만 나오는 것이 아니라 hidden state라는 것이 존재하며, cell state는 말 그대로 다음 cell에 전달되는 state이고 hidden state는 cell안에서 동작할 때, 처음에 input vector와 concatenate가 되어 연산이 일어나는 vector이며 실제 어떤 출력 y를 예측할 때 사용 되는 vector이다. 전체적인 구조는 아래의 그림과 같다.  \n",
    "  \n",
    "참고 : http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "![Alt text](http://i.imgur.com/ddP1mwL.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=2, h=2) 2 <bound method _RNNCell.zero_state of <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x0000016933F48A58>>\n",
      "[[[ 1.  0.  0.  0.]]] (1, 1, 4)\n",
      "states LSTMStateTuple(c=array([[ 0.11595624,  0.11369593]], dtype=float32), h=array([[ 0.05820915,  0.05193908]], dtype=float32))\n",
      "outputs [[[ 0.05820915  0.05193908]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('basic_lstm_one_cell'):\n",
    "# One cell lstm input_dim (4) -> output_dim (2)\n",
    "\n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "    print(cell.state_size, cell.output_size, cell.zero_state) \n",
    "    # lstm의 경우 cell state와 hidden state (output)가 cell에서 산출된다.\n",
    "    \n",
    "    x_data = np.array([[h]], dtype = np.float32) # x_data = [[[1,0,0,0]]]\n",
    "    print(x_data, x_data.shape)\n",
    "    \n",
    "    # forward\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_data, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_hidden_states = sess.run(states)\n",
    "    \n",
    "    print('states', cell_hidden_states) \n",
    "    # c가 cell state, h가 hidden state (output)\n",
    "    # cell state의 경우 sequence의 마지막에서 다음의 무언가에 전달하는 값\n",
    "    # hidden state (output)의 경우 sequence의 마지막에서 산출되는 값\n",
    "    print('outputs', outputs.eval())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Unfolding n sequence : RNN\n",
    "아래의 코드는 다음과 같은 경우이며 sequence_length = 5로 sequence가 주어지면 cell state의 값들도 sequence의 형태로 산출한다.\n",
    "![Alt text](http://i.imgur.com/YSQFFUo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "[[[ 1.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  1.]]] (1, 5, 4)\n",
      "cell states [[ 0.07925642 -0.03518274]]\n",
      "outputs [[[-0.6945461  -0.62356317]\n",
      "  [-0.09338739 -0.13748398]\n",
      "  [ 0.4579778   0.25762054]\n",
      "  [ 0.47230816  0.38231286]\n",
      "  [ 0.07925642 -0.03518274]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('sequence_case_RNN'):\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "    print(cell.state_size, cell.output_size)\n",
    "    \n",
    "    x_sequence = np.array([[h, e, l, l ,o]], dtype = np.float32)\n",
    "    print(x_sequence, x_sequence.shape)\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_sequence, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('cell states', states.eval())\n",
    "    # cell states의 경우 최종 sequence에서 다음의 무언가에 전달하는 값!\n",
    "    print('outputs', outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfolding n sequence : LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=2, h=2) 2 <bound method _RNNCell.zero_state of <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x0000016934667AC8>>\n",
      "[[[ 1.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  1.]]] (1, 5, 4)\n",
      "states LSTMStateTuple(c=array([[-0.21913829,  0.46065116]], dtype=float32), h=array([[-0.0914715 ,  0.14865206]], dtype=float32))\n",
      "outputs [[[ 0.00469851 -0.04158599]\n",
      "  [-0.03217997 -0.1067911 ]\n",
      "  [-0.04807003  0.05999256]\n",
      "  [-0.03346811  0.1466434 ]\n",
      "  [-0.0914715   0.14865206]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('sequence_case_LSTM'):\n",
    "\n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "    print(cell.state_size, cell.output_size, cell.zero_state)\n",
    "    \n",
    "    x_sequence = np.array([[h, e, l, l ,o]], dtype = np.float32)\n",
    "    print(x_sequence, x_sequence.shape)\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_sequence, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_hidden_states = sess.run(states)\n",
    "    \n",
    "    print('states', cell_hidden_states)\n",
    "    # cell state의 경우 sequence의 마지막에서 다음의 무언가에 전달하는 값\n",
    "    # hidden state (output)의 경우 sequence의 마지막에서 산출되는 값\n",
    "    print('outputs', outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfolding n sequence with batch input  : RNN\n",
    "![Alt text](http://i.imgur.com/WJX8EAU.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  1.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]]] (3, 5, 4)\n",
      "cell states [[-0.54370898  0.51788414]\n",
      " [ 0.19359617  0.46263412]\n",
      " [ 0.10291118  0.60138834]]\n",
      "outputs [[[ 0.63310111  0.44483227]\n",
      "  [ 0.34729737  0.81523305]\n",
      "  [ 0.1166632   0.5816775 ]\n",
      "  [ 0.18876496  0.47139043]\n",
      "  [-0.54370898  0.51788414]]\n",
      "\n",
      " [[ 0.5116123   0.6163646 ]\n",
      "  [-0.61230969  0.65871525]\n",
      "  [ 0.40001139  0.01559334]\n",
      "  [ 0.10085381  0.61242771]\n",
      "  [ 0.19359617  0.46263412]]\n",
      "\n",
      " [[ 0.22498091  0.41476288]\n",
      "  [ 0.15538515  0.52840447]\n",
      "  [ 0.47365046  0.67328405]\n",
      "  [ 0.39103985  0.77419388]\n",
      "  [ 0.10291118  0.60138834]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('3_batches_RNN'):\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    \n",
    "    x_batch = np.array([[h, e, l, l, o], [e, o ,l, l, l],[l, l, e, e, l]], dtype = np.float32)\n",
    "    print(x_batch, x_batch.shape)\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_batch, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('cell states', states.eval())\n",
    "    # 3개의 batch이므로 cell states의 값 또는 벡터가 3개 나옴\n",
    "    print('outputs', outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfolding n sequence with batch input  : LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  1.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]]] (3, 5, 4)\n",
      "states LSTMStateTuple(c=array([[-0.15954085,  0.04039727],\n",
      "       [-0.11730883, -0.14731237],\n",
      "       [-0.04427465, -0.24958855]], dtype=float32), h=array([[-0.07963151,  0.02576681],\n",
      "       [-0.04642324, -0.05068645],\n",
      "       [-0.01768298, -0.08971673]], dtype=float32))\n",
      "outputs [[[ 0.09004864  0.0528918 ]\n",
      "  [ 0.13017456 -0.05151128]\n",
      "  [ 0.04223709 -0.06684009]\n",
      "  [ 0.01344103 -0.07762972]\n",
      "  [-0.07963151  0.02576681]]\n",
      "\n",
      " [[ 0.03238416 -0.07657412]\n",
      "  [-0.07404277  0.05995721]\n",
      "  [-0.04630205 -0.0083233 ]\n",
      "  [-0.04481458 -0.03480339]\n",
      "  [-0.04642324 -0.05068645]]\n",
      "\n",
      " [[-0.01021079 -0.03488366]\n",
      "  [-0.02118519 -0.05446798]\n",
      "  [ 0.00350233 -0.13476616]\n",
      "  [ 0.02098042 -0.16105732]\n",
      "  [-0.01768298 -0.08971673]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('3_batches_LSTM'):\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_batch = np.array([[h, e, l, l, o], [e, o ,l, l, l],[l, l, e, e, l]], dtype = np.float32)\n",
    "    print(x_batch, x_batch.shape)\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_batch, dtype = tf.float32)\n",
    " \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_hidden_states = sess.run(states)\n",
    "    \n",
    "    print('states', cell_hidden_states)\n",
    "    print('outputs', outputs.eval())\n",
    "    # cell state의 경우 sequence의 마지막에서 다음의 무언가에 전달하는 값\n",
    "    # hidden state (output)의 경우 sequence의 마지막에서 산출되는 값\n",
    "    # batch (sequence 3개의 example이므로) cell state, hidden state의 값 또는 벡터가 3개씩 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  0.  1.]]\n",
      "\n",
      " [[ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  1.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]]\n",
      "\n",
      " [[ 0.  0.  1.  0.]\n",
      "  [ 0.  0.  1.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  1.  0.  0.]\n",
      "  [ 0.  0.  1.  0.]]] (3, 5, 4)\n",
      "states LSTMStateTuple(c=array([[-0.11567314,  0.15889417],\n",
      "       [ 0.02387191,  0.1483482 ],\n",
      "       [ 0.28869146,  0.42212284]], dtype=float32), h=array([[-0.06705084,  0.05426852],\n",
      "       [ 0.00918842,  0.06765675],\n",
      "       [ 0.10600475,  0.21914782]], dtype=float32))\n",
      "outputs [[[-0.00191582 -0.08889396]\n",
      "  [ 0.0662165  -0.02565779]\n",
      "  [ 0.07728618  0.08835547]\n",
      "  [ 0.07620183  0.15945849]\n",
      "  [-0.06705084  0.05426852]]\n",
      "\n",
      " [[ 0.06170494  0.04657923]\n",
      "  [-0.07225833 -0.01762054]\n",
      "  [ 0.00918842  0.06765675]\n",
      "  [ 0.          0.        ]\n",
      "  [ 0.          0.        ]]\n",
      "\n",
      " [[ 0.03495911  0.09325722]\n",
      "  [ 0.05101828  0.15713318]\n",
      "  [ 0.08525225  0.19951533]\n",
      "  [ 0.10600475  0.21914782]\n",
      "  [ 0.          0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('3_batches_dynamic_length_LSTM') as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (5). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "    print(x_data, x_data.shape)\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = rnn.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_data, sequence_length=[5,3,4], dtype=tf.float32)\n",
    "    # sequence_length arguments로 각각의 sequence마다 output의 결과를 필요한 부분만 뽑아낼 수 있다. (sequence의 앞부터)\n",
    "    # sequence_length arguments로 최종적으로 output이 나올 sequence의 끝단을 결정하면, cell states의 경우는 그 끝단에서 다음으로 전달하는 \n",
    "    # 값 또는 벡터를 산출할 수 있다.\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_hidden_states = sess.run(states)\n",
    "\n",
    "    print('states', cell_hidden_states)\n",
    "    print('outputs', outputs.eval())\n",
    "    # cell state의 경우 sequence의 마지막에서 다음의 무언가에 전달하는 값\n",
    "    # hidden state (output)의 경우 sequence의 마지막에서 산출되는 값\n",
    "    # batch (sequence 3개의 example이므로) cell state, hidden state의 값 또는 벡터가 3개씩 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the initial state (RNN, LSTM)\n",
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "initial_state\n",
      " [[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "cell states [[ 0.59695184 -0.79401386]\n",
      " [-0.40585628  0.20832153]\n",
      " [-0.4432646   0.24303824]]\n",
      "outputs [[[ 0.11470354 -0.511262  ]\n",
      "  [-0.56179035  0.36061054]\n",
      "  [-0.57698447  0.04971569]\n",
      "  [-0.47768033  0.18816011]\n",
      "  [ 0.59695184 -0.79401386]]\n",
      "\n",
      " [[-0.68042958  0.09627182]\n",
      "  [ 0.64991659 -0.80446416]\n",
      "  [-0.40964082  0.77316105]\n",
      "  [-0.70218945 -0.08972695]\n",
      "  [-0.40585628  0.20832153]]\n",
      "\n",
      " [[-0.55963206  0.39608955]\n",
      "  [-0.58745575  0.03384132]\n",
      "  [-0.60960853 -0.12756902]\n",
      "  [-0.56036544 -0.06023395]\n",
      "  [-0.4432646   0.24303824]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('initial_state_RNN'):\n",
    "    batch_size = 3\n",
    "    hidden_size = 2\n",
    "    x_batch = np.array([[h, e, l, l, o],\n",
    "                      [e, o, l, l, l],\n",
    "                      [l, l, e, e, l]], dtype=np.float32)\n",
    "    \n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "    print(cell.state_size, cell.output_size)\n",
    "    initial_state = cell.zero_state(batch_size = batch_size, dtype = tf.float32)\n",
    "    print('initial_state\\n', initial_state.eval())\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_batch, initial_state = initial_state, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print('cell states', states.eval())\n",
    "    print('outputs', outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=2, h=2) 2\n",
      "initial_state\n",
      " LSTMStateTuple(c=array([[ 0.,  0.],\n",
      "       [ 0.,  0.],\n",
      "       [ 0.,  0.]], dtype=float32), h=array([[ 0.,  0.],\n",
      "       [ 0.,  0.],\n",
      "       [ 0.,  0.]], dtype=float32))\n",
      "states LSTMStateTuple(c=array([[ 0.08994563,  0.4443832 ],\n",
      "       [ 0.38668162,  0.60645157],\n",
      "       [ 0.32665431,  0.26637641]], dtype=float32), h=array([[ 0.06036732,  0.15712595],\n",
      "       [ 0.20308964,  0.31945127],\n",
      "       [ 0.16781646,  0.16902837]], dtype=float32))\n",
      "outputs [[[ 0.08085226  0.00354403]\n",
      "  [ 0.02588757 -0.11362526]\n",
      "  [ 0.13710369  0.16714595]\n",
      "  [ 0.21389508  0.25678951]\n",
      "  [ 0.06036732  0.15712595]]\n",
      "\n",
      " [[-0.05625843 -0.10844176]\n",
      "  [-0.1963553   0.03598393]\n",
      "  [ 0.00137143  0.25870115]\n",
      "  [ 0.12408894  0.30490223]\n",
      "  [ 0.20308964  0.31945127]]\n",
      "\n",
      " [[ 0.12128529  0.21983363]\n",
      "  [ 0.20290466  0.2785309 ]\n",
      "  [ 0.14494732  0.03862848]\n",
      "  [ 0.0746925  -0.09567902]\n",
      "  [ 0.16781646  0.16902837]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('initial_state_LSTM'):\n",
    "    batch_size = 3\n",
    "    hidden_size = 2\n",
    "    x_batch = np.array([[h, e, l, l, o],\n",
    "                      [e, o, l, l, l],\n",
    "                      [l, l, e, e, l]], dtype=np.float32)\n",
    "    \n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "    print(cell.state_size, cell.output_size)\n",
    "    initial_state = cell.zero_state(batch_size = batch_size, dtype = tf.float32)\n",
    "    print('initial_state\\n', sess.run(initial_state))\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_batch, initial_state = initial_state, dtype = tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_hidden_states = sess.run(states)\n",
    "    \n",
    "    print('states', cell_hidden_states)\n",
    "    print('outputs', outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep RNN & LSTM\n",
    "One to One case로 구조를 알아본다. RNN 계열에서 cell을 stack하기위해서는 tf.contrib.rnn.MultiRNNCell을 활용한다. (이 때 cell은 미리 정해주어야한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.  0.]]] (1, 1, 4)\n",
      "Tensor(\"2_layer_RNN_MultiRNNCell/rnn/transpose:0\", shape=(1, 1, 2), dtype=float32)\n",
      "state (array([[-0.62157214,  0.43190563]], dtype=float32), array([[-0.05544733, -0.17107217]], dtype=float32))\n",
      "output [[[-0.05544733 -0.17107217]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('2_layer_RNN_MultiRNNCell'):\n",
    "    \n",
    "    x_data = np.array([[h]], dtype = np.float32)\n",
    "    print(x_data, x_data.shape)\n",
    "\n",
    "    # Make rnn\n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells = [cell] * 2, state_is_tuple = True) # 2layer\n",
    "    \n",
    "    # RNN in/out\n",
    "    output, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_data, dtype = tf.float32)\n",
    "    print(output)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_states = sess.run(states)\n",
    "    \n",
    "    print('state', cell_states) # layer를 2개로 stack 했으므로 cell state vector가 두 개 나온다.\n",
    "    print('output', output.eval()) \n",
    "    # input이 sequence가 아니라 하나의 token이므로 output이 하나온다.RNN이므로 마지막 layer의 cell state와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for each character in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  0.  0.  0.]]] (1, 1, 4)\n",
      "Tensor(\"2_layer_LSTM_MultiRNNCell/rnn/transpose:0\", shape=(1, 1, 2), dtype=float32)\n",
      "state (LSTMStateTuple(c=array([[-0.25200501, -0.02415623]], dtype=float32), h=array([[-0.14680254, -0.01400189]], dtype=float32)), LSTMStateTuple(c=array([[ 0.0541461 ,  0.00878605]], dtype=float32), h=array([[ 0.02738931,  0.00416418]], dtype=float32)))\n",
      "output [[[ 0.02738931  0.00416418]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('2_layer_LSTM_MultiRNNCell'):\n",
    "    \n",
    "    x_data = np.array([[h]], dtype = np.float32)\n",
    "    print(x_data, x_data.shape)\n",
    "\n",
    "    # Make rnn\n",
    "    hidden_size = 2\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells = [cell] * 2, state_is_tuple = True) # 2layer\n",
    "    \n",
    "    # RNN in/out\n",
    "    output, states = tf.nn.dynamic_rnn(cell = cell, inputs = x_data, dtype = tf.float32)\n",
    "    print(output)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cell_states = sess.run(states)\n",
    "    \n",
    "    print('state', cell_states) # layer를 2개로 stack 했으므로 cell state vector가 두 개 나온다.\n",
    "    print('output', output.eval()) \n",
    "    # input이 sequence가 아니라 하나의 token이므로 output이 하나온다.RNN이므로 마지막 layer의 cell state와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple bi-directional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.   1.   2.]\n",
      "  [  3.   4.   5.]\n",
      "  [  6.   7.   8.]\n",
      "  [  9.  10.  11.]\n",
      "  [ 12.  13.  14.]]\n",
      "\n",
      " [[ 15.  16.  17.]\n",
      "  [ 18.  19.  20.]\n",
      "  [ 21.  22.  23.]\n",
      "  [ 24.  25.  26.]\n",
      "  [ 27.  28.  29.]]\n",
      "\n",
      " [[ 30.  31.  32.]\n",
      "  [ 33.  34.  35.]\n",
      "  [ 36.  37.  38.]\n",
      "  [ 39.  40.  41.]\n",
      "  [ 42.  43.  44.]]] (3, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create input data\n",
    "batch_size=3\n",
    "sequence_length=5\n",
    "input_dim=3\n",
    "\n",
    "x_data = np.arange(45, dtype=np.float32).reshape(batch_size, sequence_length, input_dim)\n",
    "print(x_data, x_data.shape)  # batch, sequence_length, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states (LSTMStateTuple(c=array([[ -2.00803924e+00,   2.85866690e+00,  -8.47373784e-01,\n",
      "          6.91460371e-01,  -2.66604352e+00],\n",
      "       [ -1.50609565e+00,   4.98581409e+00,  -3.13502932e+00,\n",
      "          5.04362509e-02,  -4.71399879e+00],\n",
      "       [ -6.31192327e-01,   4.99980068e+00,  -4.64451981e+00,\n",
      "          1.29466981e-03,  -4.95562410e+00]], dtype=float32), h=array([[ -7.07124591e-01,   3.51942599e-01,  -6.85873032e-01,\n",
      "          2.02799379e-03,  -5.56596089e-03],\n",
      "       [ -8.53566408e-01,   2.84076363e-01,  -9.96212840e-01,\n",
      "          3.62268167e-07,  -2.68183230e-05],\n",
      "       [ -5.52456558e-01,   2.61948526e-01,  -9.99815166e-01,\n",
      "          1.73134840e-11,  -1.67255720e-07]], dtype=float32)), LSTMStateTuple(c=array([[  5.55543676e-02,   4.79968309e-01,   3.62226814e-01,\n",
      "         -2.68499196e-01,   1.58703709e+00],\n",
      "       [  1.20917186e-01,   5.06061554e-01,   2.34250474e-04,\n",
      "         -4.67401318e-04,   2.35634232e+00],\n",
      "       [  2.71322392e-02,   5.51785767e-01,   7.30238057e-08,\n",
      "         -4.09287566e-07,   2.68163538e+00]], dtype=float32), h=array([[  3.78238037e-02,   2.94130981e-01,   1.60248712e-01,\n",
      "         -9.51081887e-02,   5.58658123e-01],\n",
      "       [  7.53558427e-02,   4.84220777e-03,   1.61883600e-05,\n",
      "         -4.38693067e-04,   9.81975615e-01],\n",
      "       [  1.51302721e-02,   3.06189977e-05,   4.71684636e-10,\n",
      "         -4.08319949e-07,   9.90672469e-01]], dtype=float32)))\n",
      "outputs (array([[[ -9.61980149e-02,  -1.33623764e-01,  -4.98548783e-02,\n",
      "           6.99146688e-02,  -1.29467333e-02],\n",
      "        [ -2.97915131e-01,   6.24714196e-02,  -2.98920751e-01,\n",
      "           5.15532792e-02,  -5.21766283e-02],\n",
      "        [ -4.78099346e-01,   3.03069144e-01,  -4.91506696e-01,\n",
      "           2.05781385e-02,  -3.78670879e-02],\n",
      "        [ -6.04355872e-01,   3.57249409e-01,  -5.86870492e-01,\n",
      "           6.78239483e-03,  -1.56524889e-02],\n",
      "        [ -7.07124591e-01,   3.51942599e-01,  -6.85873032e-01,\n",
      "           2.02799379e-03,  -5.56596089e-03]],\n",
      "\n",
      "       [[ -2.36073881e-01,   3.23772460e-01,  -6.32447898e-01,\n",
      "           1.93496762e-05,  -2.08106008e-03],\n",
      "        [ -4.66289192e-01,   3.32108438e-01,  -8.66610408e-01,\n",
      "           1.11524159e-05,  -7.38330011e-04],\n",
      "        [ -6.51548326e-01,   3.09829116e-01,  -9.54025567e-01,\n",
      "           4.01639772e-06,  -2.37070708e-04],\n",
      "        [ -7.76155829e-01,   2.94276148e-01,  -9.85841155e-01,\n",
      "           1.24017379e-06,  -7.84589211e-05],\n",
      "        [ -8.53566408e-01,   2.84076363e-01,  -9.96212840e-01,\n",
      "           3.62268167e-07,  -2.68183230e-05]],\n",
      "\n",
      "       [[ -1.23537183e-01,   3.00478756e-01,  -7.39013851e-01,\n",
      "           8.46870130e-10,  -1.28883476e-05],\n",
      "        [ -2.60960251e-01,   2.96462148e-01,  -9.52394485e-01,\n",
      "           5.34404632e-10,  -4.29471720e-06],\n",
      "        [ -3.82043540e-01,   2.78494328e-01,  -9.92179751e-01,\n",
      "           1.94850969e-10,  -1.40548946e-06],\n",
      "        [ -4.78418440e-01,   2.69026965e-01,  -9.98777092e-01,\n",
      "           5.96035096e-11,  -4.80941651e-07],\n",
      "        [ -5.52456558e-01,   2.61948526e-01,  -9.99815166e-01,\n",
      "           1.73134840e-11,  -1.67255720e-07]]], dtype=float32), array([[[  3.78238037e-02,   2.94130981e-01,   1.60248712e-01,\n",
      "          -9.51081887e-02,   5.58658123e-01],\n",
      "        [  1.53189763e-01,   1.87217116e-01,   4.44203541e-02,\n",
      "          -6.53035790e-02,   8.18877995e-01],\n",
      "        [  1.60213426e-01,   7.89362043e-02,   6.44528959e-03,\n",
      "          -2.24716887e-02,   8.24197710e-01],\n",
      "        [  1.31488845e-01,   2.85238922e-02,   7.53780245e-04,\n",
      "          -6.76216744e-03,   6.83622360e-01],\n",
      "        [  1.01083376e-01,   9.17305239e-03,   7.53312124e-05,\n",
      "          -1.91437278e-03,   4.05461848e-01]],\n",
      "\n",
      "       [[  7.53558427e-02,   4.84220777e-03,   1.61883600e-05,\n",
      "          -4.38693067e-04,   9.81975615e-01],\n",
      "        [  5.57239503e-02,   1.72545761e-03,   1.95893290e-06,\n",
      "          -1.11350339e-04,   9.56953764e-01],\n",
      "        [  4.07694355e-02,   5.94376586e-04,   2.25508558e-07,\n",
      "          -2.79960168e-05,   8.95353973e-01],\n",
      "        [  2.95360144e-02,   1.93558022e-04,   2.39178632e-08,\n",
      "          -7.05303773e-06,   7.51167297e-01],\n",
      "        [  2.11247150e-02,   5.92760334e-05,   2.30697439e-09,\n",
      "          -1.79572339e-06,   4.56385791e-01]],\n",
      "\n",
      "       [[  1.51302721e-02,   3.06189977e-05,   4.71684636e-10,\n",
      "          -4.08319949e-07,   9.90672469e-01],\n",
      "        [  1.07900705e-02,   1.09009079e-05,   5.65525647e-11,\n",
      "          -1.00203842e-07,   9.74118114e-01],\n",
      "        [  7.66561832e-03,   3.77307288e-06,   6.50586529e-12,\n",
      "          -2.47090934e-08,   9.27530348e-01],\n",
      "        [  5.40449936e-03,   1.22929373e-06,   6.85332542e-13,\n",
      "          -6.16396800e-09,   8.01339388e-01],\n",
      "        [  3.74370138e-03,   3.71716567e-07,   6.48010766e-14,\n",
      "          -1.56090252e-09,   5.04163504e-01]]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('simple_bi_directional_LSTM'):\n",
    "    \n",
    "    # bi-directional LSTM\n",
    "    hidden_size = 5\n",
    "    cell_fw = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "    cell_bw = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, forget_bias = 0.9, state_is_tuple = True)\n",
    "\n",
    "    # bidirectional_dynamic_rnn의 sequence_length option은 필수 arguments, not optional\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw = cell_fw, cell_bw = cell_bw, inputs = x_data, dtype = tf.float32,\n",
    "                                                       sequence_length = [5,5,5])\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #outputs, cell states, hidden states가 각 배치마다 2개씩 나오는 데, 이는 encoder part, decoder part에 대해서 나오는 것이기 때문이다.\n",
    "    print('states', sess.run(states))\n",
    "    print('outputs', sess.run(outputs)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   2.]\n",
      " [  3.   4.   5.]\n",
      " [  6.   7.   8.]\n",
      " [  9.  10.  11.]\n",
      " [ 12.  13.  14.]\n",
      " [ 15.  16.  17.]\n",
      " [ 18.  19.  20.]\n",
      " [ 21.  22.  23.]\n",
      " [ 24.  25.  26.]\n",
      " [ 27.  28.  29.]\n",
      " [ 30.  31.  32.]\n",
      " [ 33.  34.  35.]\n",
      " [ 36.  37.  38.]\n",
      " [ 39.  40.  41.]\n",
      " [ 42.  43.  44.]]\n",
      "[[[   25.    28.    31.    34.    37.]\n",
      "  [   70.    82.    94.   106.   118.]\n",
      "  [  115.   136.   157.   178.   199.]\n",
      "  [  160.   190.   220.   250.   280.]\n",
      "  [  205.   244.   283.   322.   361.]]\n",
      "\n",
      " [[  250.   298.   346.   394.   442.]\n",
      "  [  295.   352.   409.   466.   523.]\n",
      "  [  340.   406.   472.   538.   604.]\n",
      "  [  385.   460.   535.   610.   685.]\n",
      "  [  430.   514.   598.   682.   766.]]\n",
      "\n",
      " [[  475.   568.   661.   754.   847.]\n",
      "  [  520.   622.   724.   826.   928.]\n",
      "  [  565.   676.   787.   898.  1009.]\n",
      "  [  610.   730.   850.   970.  1090.]\n",
      "  [  655.   784.   913.  1042.  1171.]]]\n"
     ]
    }
   ],
   "source": [
    "# flattern based softmax\n",
    "hidden_size=3\n",
    "sequence_length=5\n",
    "batch_size=3\n",
    "num_classes=5\n",
    "\n",
    "x_data = x_data.reshape(-1, hidden_size)\n",
    "print(x_data)\n",
    "\n",
    "softmax_w = np.arange(15, dtype=np.float32).reshape(hidden_size, num_classes)\n",
    "outputs = np.matmul(x_data, softmax_w)\n",
    "outputs = outputs.reshape(-1, sequence_length, num_classes) # batch, seq, class\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  calculate seq2seq loss simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.596759\n"
     ]
    }
   ],
   "source": [
    "# [batch_size, sequence_length]\n",
    "y_data = tf.constant([[1, 1, 1]])\n",
    "\n",
    "# [batch_size, sequence_length, emb_dim ]\n",
    "prediction = tf.constant([[[0.2, 0.7], [0.6, 0.2], [0.2, 0.9]]], dtype=tf.float32)\n",
    "\n",
    "# [batch_size * sequence_length]\n",
    "weights = tf.constant([[1, 1, 1]], dtype=tf.float32)\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=prediction, targets=y_data, weights=weights)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Loss: \", sequence_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "Loss1:  0.513015 Loss2:  0.371101 Loss3:  0.313262 Loss4:  0.646595\n"
     ]
    }
   ],
   "source": [
    "# [batch_size, sequence_length]\n",
    "y_data = tf.constant([[1, 1, 1]])\n",
    "\n",
    "# [batch_size, sequence_length, emb_dim ]\n",
    "prediction1 = tf.constant([[[0.3, 0.7], [0.3, 0.7], [0.3, 0.7]]], dtype=tf.float32)\n",
    "print(prediction1.shape)\n",
    "prediction2 = tf.constant([[[0.1, 0.9], [0.1, 0.9], [0.1, 0.9]]], dtype=tf.float32)\n",
    "\n",
    "prediction3 = tf.constant([[[0, 1], [0, 1], [0, 1]]], dtype=tf.float32)\n",
    "prediction4 = tf.constant([[[0, 1], [1, 0], [0, 1]]], dtype=tf.float32)\n",
    "\n",
    "# [batch_size * sequence_length]\n",
    "weights = tf.constant([[1, 1, 1]], dtype=tf.float32)  # weigths 해당하는 sequence의 단위별 loss에 대한 가중치이다.\n",
    "\n",
    "sequence_loss1 = tf.contrib.seq2seq.sequence_loss(logits = prediction1, targets = y_data, weights = weights)\n",
    "sequence_loss2 = tf.contrib.seq2seq.sequence_loss(logits = prediction2, targets = y_data, weights = weights)\n",
    "sequence_loss3 = tf.contrib.seq2seq.sequence_loss(logits = prediction3, targets = y_data, weights = weights)\n",
    "sequence_loss4 = tf.contrib.seq2seq.sequence_loss(logits = prediction4, targets = y_data, weights = weights)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Loss1: \", sequence_loss1.eval(),\n",
    "      \"Loss2: \", sequence_loss2.eval(),\n",
    "      \"Loss3: \", sequence_loss3.eval(),\n",
    "      \"Loss4: \", sequence_loss4.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
