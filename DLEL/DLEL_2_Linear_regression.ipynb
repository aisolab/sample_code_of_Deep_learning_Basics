{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모두를 위한 머신러닝/딥러닝 강의\n",
    "김성훈 교수님의 모두를 위한 머신러닝/딥러닝 강의 중 lab 강의 코드입니다.\n",
    "## Lab2 Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression (without Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.82329 [ 2.12867713] [-0.85235673]\n",
      "200 0.0699669 [ 1.30721498] [-0.69837153]\n",
      "400 0.0267168 [ 1.18984008] [-0.43155104]\n",
      "600 0.0102018 [ 1.11730957] [-0.26667225]\n",
      "800 0.00389554 [ 1.07249033] [-0.16478731]\n",
      "1000 0.00148752 [ 1.04479468] [-0.10182867]\n",
      "1200 0.000568001 [ 1.02768028] [-0.06292392]\n",
      "1400 0.000216893 [ 1.01710486] [-0.03888337]\n",
      "1600 8.28209e-05 [ 1.01056981] [-0.02402756]\n",
      "1800 3.16242e-05 [ 1.00653136] [-0.01484742]\n",
      "2000 1.20761e-05 [ 1.00403607] [-0.00917497]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777) # for reproducibility\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# Try to find values for W and b to compute y_data = x_data * W + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let TensorFlow figure it out\n",
    "W = tf.Variable(tf.random_normal(shape = [1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal(shape = [1]), name = 'bias')\n",
    "\n",
    "# Our hypothesis XW + b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = opt.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "\n",
    "# Learns best fit W:[ 1.],  b:[ 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear regression (with Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.07663 [ 1.50679803] [ 1.20121849]\n",
      "200 0.0368028 [ 0.7771892] [ 0.50650144]\n",
      "400 0.0140531 [ 0.86231649] [ 0.31298706]\n",
      "600 0.00536615 [ 0.91491997] [ 0.19340698]\n",
      "800 0.00204906 [ 0.94742572] [ 0.11951366]\n",
      "1000 0.000782432 [ 0.96751231] [ 0.07385215]\n",
      "1200 0.000298772 [ 0.97992462] [ 0.04563618]\n",
      "1400 0.000114084 [ 0.98759466] [ 0.02820027]\n",
      "1600 4.35624e-05 [ 0.99233437] [ 0.01742587]\n",
      "1800 1.66348e-05 [ 0.99526304] [ 0.0107682]\n",
      "2000 6.35198e-06 [ 0.99707288] [ 0.00665409]\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "# Try to find values for W and b to compute y_data = W * x_data + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let's use TensorFlow to figure it out\n",
    "W = tf.Variable(tf.random_normal(shape = [1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal(shape = [1]), name = 'bias')\n",
    "\n",
    "# Now we can use X and Y in place of x_data and y_data\n",
    "# # placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "\n",
    "# shape = [None]으로 데이터의 개수를 명시적으로 정하지않음, 나중에 mini-batch learning 할때 유용\n",
    "# 행렬이라면 shape = [None, dim] 이런식으로 정하면됨 (dim은 데이터의 차원)\n",
    "X = tf.placeholder(tf.float32, shape = [None]) \n",
    "Y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "# Our hypothesis XW + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = opt.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for iter in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train], feed_dict= {X : [1,2,3], Y : [1,2,3]})\n",
    "    \n",
    "    if iter % 200 == 0:\n",
    "        print(iter, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.50225794  3.49641776]\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict= {X : [1.5, 3.5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
